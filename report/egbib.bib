@article{fang_computer_2020,
  title    = {Computer vision for behaviour-based safety in construction: {A} review and future directions},
  volume   = {43},
  issn     = {1474-0346},
  url      = {https://www.sciencedirect.com/science/article/pii/S1474034619305531},
  doi      = {https://doi.org/10.1016/j.aei.2019.100980},
  abstract = {The process of identifying and bringing to the fore people’s unsafe behaviour is a core function of implementing a behaviour-based safety (BBS) program in construction. This can be a labour-intensive and challenging process but is needed to enable people to reflect and learn about how their unsafe actions can jeopardise not only their safety but that of their co-workers. With advances being made in computer vision, the capability exists to automatically capture and identify unsafe behaviour and hazards in real-time from two-dimensional (2D) digital images/videos. The corollary developments in computer vision have stimulated a wealth of research in construction to examine its potential application to practice. Hindering the application of computer vision in construction has been its inability to accurately, and generalise the detection of objects. To address this shortcoming, developments in deep learning have provided computer vision with the ability to improve the accuracy, reliability and ability to generalise object detection and therefore its usage in construction. In this paper we review the developments of computer vision studies that have been used to identify unsafe behaviour from 2D images that arises on construction sites. Then, in light of advances made with deep learning, we examine and discuss its integration with computer vision to support BBS. We also suggest that future computer-vision research should aim to support BBS by being able to: (1) observe and record unsafe behaviour; (2) understand why people act unsafe behaviour; (3) learn from unsafe behaviour; and (4) predict unsafe behaviour.},
  journal  = {Advanced Engineering Informatics},
  author   = {Fang, Weili and Love, Peter E. D. and Luo, Hanbin and Ding, Lieyun},
  year     = {2020},
  keywords = {Behaviour-based safety, Computer vision, Convolutional neural network, Deep learning, Unsafe behaviour},
  pages    = {100980}
}

@misc{ibmWhatConvolutional,
  author       = {IBM},
  title        = {{W}hat are {C}onvolutional {N}eural {N}etworks? | {I}{B}{M} --- ibm.com},
  howpublished = {\url{https://www.ibm.com/topics/convolutional-neural-networks}},
  year         = {},
  note         = {[Accessed 12-10-2024]}
}

@misc{cifar-10,
  author    = {Will Cukierski},
  title     = {CIFAR-10 - Object Recognition in Images},
  publisher = {Kaggle},
  year      = {2013},
  url       = {https://kaggle.com/competitions/cifar-10}
}

@article{pooling_diag,
  author  = {Minfei, Liang and Gan, Yidong and Chang, Ze and Wan, Zhi and Schlangen, Erik and Šavija, Branko},
  year    = {2022},
  month   = {02},
  pages   = {106681},
  title   = {Microstructure-informed deep convolutional neural network for predicting short-term creep modulus of cement paste},
  volume  = {152},
  journal = {Cement and Concrete Research},
  doi     = {10.1016/j.cemconres.2021.106681}
}

@article{Yamashita2018,
  title     = {Convolutional neural networks: an overview and application in radiology},
  volume    = {9},
  issn      = {1869-4101},
  url       = {http://dx.doi.org/10.1007/s13244-018-0639-9},
  doi       = {10.1007/s13244-018-0639-9},
  number    = {4},
  journal   = {Insights into Imaging},
  publisher = {Springer Science and Business Media LLC},
  author    = {Yamashita,  Rikiya and Nishio,  Mizuho and Do,  Richard Kinh Gian and Togashi,  Kaori},
  year      = {2018},
  month     = jun,
  pages     = {611–629}
}

@incollection{REN202351,
  title     = {Chapter 3 - Calculus and optimization},
  editor    = {Jingli Ren and Haiyan Wang},
  booktitle = {Mathematical Methods in Data Science},
  publisher = {Elsevier},
  pages     = {51-89},
  year      = {2023},
  isbn      = {978-0-443-18679-0},
  doi       = {https://doi.org/10.1016/B978-0-44-318679-0.00009-0},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780443186790000090},
  author    = {Jingli Ren and Haiyan Wang},
  keywords  = {Gradient, Chain rule, Unconstrained optimization, Gradient descent, Machine learning methods, Logistic regression, Support vector machines, Neural networks, Backpropagation},
  abstract  = {We start with a review of differential calculus. We highlight a few key results in calculus including the extreme value theorem, the mean value theorem, and the chain rule, which will play an important role for data science and machine learning. We also discuss a number of optimization results and machine learning methods including logistic regression, support vector machines, and neural networks.}
}
@misc{torontoCIFAR10CIFAR100,
  author       = {Alex Krizhevsky},
  title        = {{C}{I}{F}{A}{R}-10 and {C}{I}{F}{A}{R}-100 datasets --- cs.toronto.edu},
  howpublished = {\url{https://www.cs.toronto.edu/~kriz/cifar.html}},
  year         = {2012},
  note         = {[Accessed 20-10-2024]}
}

@article{Rumelhart1986,
  title     = {Learning representations by back-propagating errors},
  volume    = {323},
  issn      = {1476-4687},
  url       = {http://dx.doi.org/10.1038/323533a0},
  doi       = {10.1038/323533a0},
  number    = {6088},
  journal   = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author    = {Rumelhart,  David E. and Hinton,  Geoffrey E. and Williams,  Ronald J.},
  year      = {1986},
  month     = oct,
  pages     = {533–536}
}

@misc{Oh_2022,
  title     = {What is Cuda?},
  url       = {https://blogs.nvidia.com/blog/what-is-cuda-2/},
  journal   = {NVIDIA Blog},
  publisher = {Nvidia},
  author    = {Oh, Fred},
  year      = {2022},
  month     = {Jan}
} 
@article{LINKON2021100582,
  title    = {Deep learning in prostate cancer diagnosis and Gleason grading in histopathology images: An extensive study},
  journal  = {Informatics in Medicine Unlocked},
  volume   = {24},
  pages    = {100582},
  year     = {2021},
  issn     = {2352-9148},
  doi      = {https://doi.org/10.1016/j.imu.2021.100582},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352914821000721},
  author   = {Ali Hasan Md. Linkon and Md. Mahir Labib and Tarik Hasan and Mozammal Hossain and Marium-E- Jannat},
  keywords = {Deep learning, Convolutional neural network, Computer-aided detection, Medical imaging, Prostate cancer detection, Gleason grading},
  abstract = {Among American men, prostate cancer is the cause of the second-highest death by any cancer. It is also the most common cancer in men worldwide, and the annual numbers are quite alarming. The most prognostic marker for prostate cancer is the Gleason grading system on histopathology images. Pathologists determine the Gleason grade on stained tissue specimens of Hematoxylin and Eosin (H&E) based on tumor structural growth patterns from whole slide images. Recent advances in Computer-Aided Detection (CAD) using deep learning have brought the immense scope of automatic detection and recognition at very high accuracy in prostate cancer like other medical diagnoses and prognoses. Automated deep learning systems have delivered promising results from histopathological images to accurate grading of prostate cancer. Many studies have shown that deep learning strategies can achieve better outcomes than simpler systems that make use of pathology samples. This article aims to provide an insight into the gradual evolution of deep learning in detecting prostate cancer and Gleason grading. This article also evaluates a comprehensive, synthesized overview of the current state and existing methodological approaches as well as unique insights in prostate cancer detection using deep learning. We have also described research findings, current limitations, and future avenues for research. We have tried to make this paper applicable to deep learning communities and hope it will encourage new collaborations to create dedicated applications and improvements for prostate cancer detection and Gleason grading.}
}
@misc{https://doi.org/10.48550/arxiv.1512.03385,
  doi       = {10.48550/ARXIV.1512.03385},
  url       = {https://arxiv.org/abs/1512.03385},
  author    = {He,  Kaiming and Zhang,  Xiangyu and Ren,  Shaoqing and Sun,  Jian},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title     = {Deep Residual Learning for Image Recognition},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{Zafar_Tzanidou_Burton_Patel_Araujo,
  title     = {Hands-on convolutional neural networks with TensorFlow},
  url       = {https://www.oreilly.com/library/view/hands-on-convolutional-neural/9781789130331/7f34b72e-f571-49d2-a37a-4ed6f8011c93.xhtml},
  journal   = {O’Reilly Online Learning},
  publisher = {Packt Publishing},
  author    = {Zafar, Iffat and Tzanidou, Giounona and Burton, Richard and Patel, Nimesh and Araujo, Leonardo}
} 